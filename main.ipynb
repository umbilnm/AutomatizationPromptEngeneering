{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "\n",
    "from utils.loader import llm, emb_fn, strings\n",
    "from utils.utils import prepare_data, set_all_seeds, save_predictions\n",
    "from utils.optimizer import Protegi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprepare_data\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/umbilnm/python_ml/AutomatizationPromptEngeneering/data/spam.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m]) \n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/umbilnm/python_ml/AutomatizationPromptEngeneering/data/spam_100.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m      3\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m messages \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_data' is not defined"
     ]
    }
   ],
   "source": [
    "prepare_data('spam', '/home/umbilnm/python_ml/AutomatizationPromptEngeneering/data/spam.csv', [100, 1000]) \n",
    "df = pd.read_csv('/home/umbilnm/python_ml/AutomatizationPromptEngeneering/data/spam_100.csv').drop(\n",
    "    columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4']\n",
    ")\n",
    "messages = df['v2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = strings['templates']['prediction_template']\n",
    "template = PromptTemplate(template=template, input_variables=['message'])\n",
    "\n",
    "preds = []\n",
    "for message in tqdm(messages):\n",
    "    prediction = llm.invoke(template.format(message=message)).content\n",
    "    preds.append(prediction)\n",
    "    df['predictions'] = 'ham' if prediction=='No' else 'spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "df['predictions'] = preds\n",
    "df['predictions'] = df['predictions'].apply(lambda x: 0 if x=='No' else 1)\n",
    "df['v1'] = df['v1'].apply(lambda x: 0 if x=='ham' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.read_csv('data/predistions/first_predictions.csv')\n",
    "df = pd.read_csv('data/spam_100.csv').drop(columns=[f'Unnamed: {i}' for i in range(2, 5)])\n",
    "df['preds'] = preds_df['predictions']\n",
    "df['v1'] = df['v1'].apply(lambda x: 1 if x=='spam' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.82\n",
      "Recall = 1.00\n",
      "Precision = 0.40\n",
      "F1 = 0.57\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(df['v1'], df['predictions'])\n",
    "recall = recall_score(df['v1'], df['predictions'])\n",
    "f1 = f1_score(df['v1'], df['predictions'])\n",
    "precision = precision_score(df['v1'], df['predictions'])\n",
    "print(f'Accuracy = {accuracy:.2f}\\nRecall = {recall:.2f}\\nPrecision = {precision:.2f}\\nF1 = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protegi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.read_csv('data/predistions/first_predictions.csv')\n",
    "df = pd.read_csv('data/spam_100.csv').drop(columns=[f'Unnamed: {i}' for i in range(2, 5)])\n",
    "prot = Protegi()\n",
    "prompt = strings['templates']['prediction_template']\n",
    "sample= df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_sampled_task_sections, new_task_sections =prot.expand_candidates(prompts=[prompt], df=sample, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('content', 'Determine if the following message is spam or not.'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 11,\n",
       "    'prompt_tokens': 39,\n",
       "    'total_tokens': 50},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-3387615a-9673-4a3e-81bd-50b5f66e4c93-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Can you confirm if the message below is spam?\\nMessage: {message}'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 15,\n",
       "    'prompt_tokens': 35,\n",
       "    'total_tokens': 50},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-19109500-ea72-4b66-a3ac-38c7dc6af444-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Assess the content of the message to determine whether it is spam or not.'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 16,\n",
       "    'prompt_tokens': 43,\n",
       "    'total_tokens': 59},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-a8c6a0ef-c8b7-4b0e-a63d-b297b6bfa58c-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Please provide a one-word answer indicating whether the following message is spam. Use \"Yes\" if it is spam, and \"No\" if it is not. \\nMessage: {message}'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 38,\n",
       "    'prompt_tokens': 58,\n",
       "    'total_tokens': 96},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-2f3f7bc0-607d-429a-ab91-830e5857025a-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Please indicate whether the message is spam with a single word response: \"Yes\" for spam, \"No\" for not spam.\\nMessage: {message}'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 31,\n",
       "    'prompt_tokens': 65,\n",
       "    'total_tokens': 96},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-0c7f63e0-929a-41d5-9588-90d3991c7bb4-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Indicate whether the following message is spam or not by providing a one-word answer: \"Yes\" for spam, \"No\" for not spam.\\nMessage: {message}'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 35,\n",
       "    'prompt_tokens': 59,\n",
       "    'total_tokens': 94},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-80394bb7-8def-4649-a7ce-0451d45cfa52-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Indicate whether the following message is spam or not spam by providing a one-word answer: \"Yes\" for spam, \"No\" for not spam.\\nMessage: {message}'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 36,\n",
       "    'prompt_tokens': 63,\n",
       "    'total_tokens': 99},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-67f045f8-7d39-4683-a6ce-54a38ed52cd3-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Please reply with a single word, \"Yes\" if the message is spam, or \"No\" if it is not.'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 25,\n",
       "    'prompt_tokens': 57,\n",
       "    'total_tokens': 82},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-3b7d01a5-9a17-4c66-a656-54a3daa0517d-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', []),\n",
       " ('content',\n",
       "  'Indicate whether the following message is spam or not by replying with a single word: \"Yes\" for spam, \"No\" for not spam.\\nMessage: {message}'),\n",
       " ('additional_kwargs', {}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'completion_tokens': 36,\n",
       "    'prompt_tokens': 58,\n",
       "    'total_tokens': 94},\n",
       "   'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_fingerprint': 'fp_77a673219d',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-0577abab-cd8d-4963-9441-2a59715de7cc-0'),\n",
       " ('example', False),\n",
       " ('tool_calls', []),\n",
       " ('invalid_tool_calls', [])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_sampled_task_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
